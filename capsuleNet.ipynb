{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import combine_images\n",
    "from PIL import Image\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "args={\n",
    "'epochs':200,\n",
    "'batch_size':32,\n",
    "'lr':0.001, #Initial learning rate\n",
    "'lr_decay':0.9, #The value multiplied by lr at each epoch. Set a larger value for larger epochs\n",
    "'lam_recon':0.392, #The coefficient for the loss of decoder\n",
    "'routings':3, #Number of iterations used in routing algorithm. should > 0\n",
    "'shift_fraction':0.2, #Fraction of pixels to shift at most in each direction.\n",
    "'debug':False, #Save weights by TensorBoard\n",
    "'save_dir':'./result',\n",
    "'testing':False, #Test the trained model on testing dataset\n",
    "'weights':None, #The path of the saved weights. Should be specified when testing\n",
    "'gpus':2\n",
    "}\n",
    "args=dotdict(args)\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8751 images belonging to 5 classes.\n",
      "Found 3753 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    horizontal_flip=True,\n",
    "                                    rotation_range = args.shift_fraction,\n",
    "                                    zoom_range = args.shift_fraction,\n",
    "                                    width_shift_range = args.shift_fraction,\n",
    "                                    height_shift_range = args.shift_fraction)\n",
    "#generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "train_set = train_datagen.flow_from_directory(\"./data/train/\",\n",
    "                                                target_size = (64, 64),\n",
    "                                                batch_size = args.batch_size,\n",
    "                                                class_mode = 'categorical')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(\"./data/test/\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 3753, #args.batch_size,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))\n",
    "def train(model, args):\n",
    "    \"\"\"\n",
    "    Training a CapsuleNet\n",
    "    :param model: the CapsuleNet model\n",
    "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
    "    :param args: arguments\n",
    "    :return: The trained model\n",
    "    \"\"\"\n",
    "    # callbacks\n",
    "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
    "    tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs',\n",
    "                               batch_size=args.batch_size, histogram_freq=int(args.debug))\n",
    "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/model-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
    "                                           save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., args.lam_recon],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    \"\"\"\n",
    "    # Training without data augmentation:\n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    \"\"\"\n",
    "\n",
    "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
    "    \n",
    "    def train_generator(batch_size, shift_fraction=0.2):\n",
    "        train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                           horizontal_flip=True,\n",
    "                                           rotation_range = shift_fraction,\n",
    "                                           zoom_range = shift_fraction,\n",
    "                                           width_shift_range = shift_fraction,\n",
    "                                           height_shift_range = shift_fraction,)\n",
    "        #generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "        generator = train_datagen.flow_from_directory(\"./data/train/\",\n",
    "                                                     target_size = (64, 64),\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     class_mode = 'categorical')\n",
    "        while 1:\n",
    "            x_batch, y_batch = generator.next()\n",
    "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "    \n",
    "    \n",
    "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "    x_test, y_test = test_set.next()\n",
    "    model.fit_generator(generator=train_generator(args.batch_size,args.shift_fraction),\n",
    "                        steps_per_epoch=int(len(train_set.classes) / args.batch_size),\n",
    "                        epochs=args.epochs,\n",
    "                        validation_data = [[x_test, y_test], [y_test, x_test]],\n",
    "                        callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
    "\n",
    "    model.save(args.save_dir + '/trained_model.h5')\n",
    "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
    "\n",
    "    from utils import plot_log\n",
    "    plot_log(args.save_dir + '/log.csv', show=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 56, 56, 256)  62464       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 24, 24, 256)  5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 18432, 8)     0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 18432, 8)     0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 5, 16)        11796480    primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_13 (Mask)                  (None, 80)           0           digitcaps[0][0]                  \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 5)            0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 64, 64, 3)    13161984    mask_13[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 30,329,600\n",
      "Trainable params: 30,329,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#define model\n",
    "def CapsNet(input_shape, n_class, routings):\n",
    "    \"\"\"\n",
    "    A Capsule Network on MNIST.\n",
    "    :param input_shape: data shape, 3d, [width, height, channels]\n",
    "    :param n_class: number of classes\n",
    "    :param routings: number of routing iterations\n",
    "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "            `eval_model` can also be used for training.\n",
    "    \"\"\"\n",
    "    x = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "                             name='digitcaps')(primarycaps)\n",
    "\n",
    "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "    # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, 16))\n",
    "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model, eval_model, manipulate_model\n",
    "\n",
    "model, eval_model, manipulate_model = CapsNet(input_shape=train_set.image_shape,\n",
    "                                                  n_class=train_set.num_classes,\n",
    "                                                  routings=args.routings)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train or test\n",
    "if args.weights is not None:  # init the model weights with provided one\n",
    "    model.load_weights(args.weights)\n",
    "if not args.testing:\n",
    "    # define muti-gpu model\n",
    "    #multi_model = multi_gpu_model(model, gpus=args.gpus)\n",
    "    train(model=model, args=args)\n",
    "else:  # as long as weights are given, will run testing\n",
    "    if args.weights is None:\n",
    "        print('No weights are provided. Will test using random initialized weights.')\n",
    "    #manipulate_latent(manipulate_model, (x_test, y_test), args)\n",
    "    #test(model=eval_model, data=(x_test, y_test), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
